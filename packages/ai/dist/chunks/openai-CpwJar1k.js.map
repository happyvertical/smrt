{"version":3,"file":"openai-CpwJar1k.js","sources":["../../src/shared/providers/openai.ts"],"sourcesContent":["/**\n * OpenAI provider implementation\n *\n * Provides a standardized interface for interacting with OpenAI's GPT models,\n * including chat completions, text completions, embeddings, and streaming responses.\n * Supports all major OpenAI features including function calling, vision models,\n * and custom fine-tuned models.\n */\n\nimport OpenAI from 'openai';\n\nimport type {\n  AICapabilities,\n  AIInterface,\n  AIMessage,\n  AIModel,\n  AIResponse,\n  ChatOptions,\n  CompletionOptions,\n  EmbeddingOptions,\n  EmbeddingResponse,\n  OpenAIOptions,\n  TokenUsage,\n} from '../types';\nimport {\n  AIError,\n  AuthenticationError,\n  ContentFilterError,\n  ContextLengthError,\n  ModelNotFoundError,\n  RateLimitError,\n} from '../types';\n\n/**\n * OpenAI provider implementation that handles all interactions with OpenAI's API.\n * Supports GPT models, embeddings, function calling, streaming, and vision capabilities.\n */\nexport class OpenAIProvider implements AIInterface {\n  private client: OpenAI;\n  private options: OpenAIOptions;\n\n  /**\n   * Creates a new OpenAI provider instance\n   * @param options - Configuration options for the OpenAI provider\n   */\n  constructor(options: OpenAIOptions) {\n    this.options = {\n      defaultModel: 'gpt-4o',\n      ...options,\n    };\n\n    this.client = new OpenAI({\n      apiKey: this.options.apiKey,\n      baseURL: this.options.baseUrl,\n      organization: this.options.organization,\n      timeout: this.options.timeout,\n      maxRetries: this.options.maxRetries,\n      defaultHeaders: this.options.headers,\n    });\n  }\n\n  /**\n   * Generate a chat completion using OpenAI's chat models\n   * @param messages - Array of conversation messages\n   * @param options - Optional configuration for the chat completion\n   * @returns Promise resolving to the AI response with content and metadata\n   * @throws {AIError} When the API request fails or returns invalid data\n   *\n   * @example\n   * ```typescript\n   * const response = await provider.chat([\n   *   { role: 'system', content: 'You are a helpful assistant.' },\n   *   { role: 'user', content: 'What is the capital of France?' }\n   * ], {\n   *   model: 'gpt-4o',\n   *   temperature: 0.7,\n   *   maxTokens: 150\n   * });\n   * console.log(response.content); // \"Paris is the capital of France.\"\n   * ```\n   */\n  async chat(\n    messages: AIMessage[],\n    options: ChatOptions = {},\n  ): Promise<AIResponse> {\n    try {\n      const response = await this.client.chat.completions.create({\n        model: options.model || this.options.defaultModel || 'gpt-4o',\n        messages: this.mapMessagesToOpenAI(messages),\n        max_tokens: options.maxTokens,\n        temperature: options.temperature,\n        top_p: options.topP,\n        n: options.n,\n        stop: options.stop,\n        frequency_penalty: options.frequencyPenalty,\n        presence_penalty: options.presencePenalty,\n        user: options.user,\n        tools: options.tools?.map((tool) => ({\n          type: 'function' as const,\n          function: {\n            name: tool.function.name,\n            description: tool.function.description,\n            parameters: tool.function.parameters,\n          },\n        })),\n        tool_choice: this.mapToolChoice(options.toolChoice),\n        response_format: options.responseFormat,\n        seed: options.seed,\n        stream: false,\n      });\n\n      const choice = response.choices[0];\n      if (!choice) {\n        throw new AIError(\n          'No choices returned from OpenAI',\n          'NO_CHOICES',\n          'openai',\n        );\n      }\n\n      return {\n        content: choice.message.content || '',\n        usage: this.mapUsage(response.usage),\n        model: response.model,\n        finishReason: this.mapFinishReason(choice.finish_reason),\n        toolCalls: choice.message.tool_calls\n          ?.filter((call) => call.type === 'function')\n          .map((call) => ({\n            id: call.id,\n            type: 'function' as const,\n            function: {\n              name: call.function.name,\n              arguments: call.function.arguments,\n            },\n          })),\n      };\n    } catch (error) {\n      throw this.mapError(error);\n    }\n  }\n\n  /**\n   * Generate a text completion for a given prompt\n   * @param prompt - The text prompt to complete\n   * @param options - Optional configuration for the completion\n   * @returns Promise resolving to the AI response\n   * @throws {AIError} When the API request fails\n   *\n   * @example\n   * ```typescript\n   * const response = await provider.complete('The weather today is', {\n   *   model: 'gpt-4o',\n   *   maxTokens: 50,\n   *   temperature: 0.5\n   * });\n   * ```\n   */\n  async complete(\n    prompt: string,\n    options: CompletionOptions = {},\n  ): Promise<AIResponse> {\n    return this.chat([{ role: 'user', content: prompt }], {\n      model: options.model,\n      maxTokens: options.maxTokens,\n      temperature: options.temperature,\n      topP: options.topP,\n      n: options.n,\n      stop: options.stop,\n      stream: options.stream,\n      onProgress: options.onProgress,\n    });\n  }\n\n  /**\n   * Generate embeddings for the given text(s)\n   * @param text - Single text string or array of texts to embed\n   * @param options - Optional configuration for embeddings\n   * @returns Promise resolving to embeddings response with vector arrays\n   * @throws {AIError} When the API request fails\n   *\n   * @example\n   * ```typescript\n   * // Single text embedding\n   * const response1 = await provider.embed('Hello world');\n   * console.log(response1.embeddings[0]); // Array of numbers\n   *\n   * // Multiple text embeddings\n   * const response2 = await provider.embed(['Text 1', 'Text 2']);\n   * console.log(response2.embeddings.length); // 2\n   * ```\n   */\n  async embed(\n    text: string | string[],\n    options: EmbeddingOptions = {},\n  ): Promise<EmbeddingResponse> {\n    try {\n      const input = Array.isArray(text) ? text : [text];\n      const response = await this.client.embeddings.create({\n        model: options.model || 'text-embedding-3-small',\n        input,\n        encoding_format: options.encodingFormat,\n        dimensions: options.dimensions,\n        user: options.user,\n      });\n\n      return {\n        embeddings: response.data.map((item) => item.embedding),\n        usage: this.mapUsage(response.usage),\n        model: response.model,\n      };\n    } catch (error) {\n      throw this.mapError(error);\n    }\n  }\n\n  /**\n   * Stream a chat completion response in real-time\n   * @param messages - Array of conversation messages\n   * @param options - Optional configuration for the chat completion\n   * @yields Individual content chunks as they arrive\n   * @throws {AIError} When the streaming request fails\n   *\n   * @example\n   * ```typescript\n   * for await (const chunk of provider.stream([\n   *   { role: 'user', content: 'Write a story about AI' }\n   * ])) {\n   *   process.stdout.write(chunk);\n   * }\n   * ```\n   */\n  async *stream(\n    messages: AIMessage[],\n    options: ChatOptions = {},\n  ): AsyncIterable<string> {\n    try {\n      const stream = await this.client.chat.completions.create({\n        model: options.model || this.options.defaultModel || 'gpt-4o',\n        messages: this.mapMessagesToOpenAI(messages),\n        max_tokens: options.maxTokens,\n        temperature: options.temperature,\n        top_p: options.topP,\n        stop: options.stop,\n        frequency_penalty: options.frequencyPenalty,\n        presence_penalty: options.presencePenalty,\n        user: options.user,\n        stream: true,\n      });\n\n      for await (const chunk of stream) {\n        const content = chunk.choices[0]?.delta?.content;\n        if (content) {\n          if (options.onProgress) {\n            options.onProgress(content);\n          }\n          yield content;\n        }\n      }\n    } catch (error) {\n      throw this.mapError(error);\n    }\n  }\n\n  /**\n   * Count the number of tokens in the given text\n   * @param text - The text to count tokens for\n   * @returns Promise resolving to the estimated token count\n   *\n   * @remarks\n   * OpenAI doesn't provide a direct token counting API, so this is an approximation\n   * based on the general rule of ~4 characters per token. For precise counting,\n   * consider using a dedicated tokenizer library.\n   *\n   * @example\n   * ```typescript\n   * const count = await provider.countTokens('Hello, world!');\n   * console.log(count); // Approximately 4 tokens\n   * ```\n   */\n  async countTokens(text: string): Promise<number> {\n    // OpenAI doesn't provide a direct token counting API\n    // This is an approximation based on the general rule of ~4 characters per token\n    return Math.ceil(text.length / 4);\n  }\n\n  /**\n   * Get a list of available OpenAI models\n   * @returns Promise resolving to an array of model information\n   * @throws {AIError} When the API request fails\n   *\n   * @example\n   * ```typescript\n   * const models = await provider.getModels();\n   * const gptModels = models.filter(m => m.id.includes('gpt'));\n   * ```\n   */\n  async getModels(): Promise<AIModel[]> {\n    try {\n      const response = await this.client.models.list();\n      return response.data\n        .filter(\n          (model) =>\n            model.id.includes('gpt') || model.id.includes('text-embedding'),\n        )\n        .map((model) => ({\n          id: model.id,\n          name: model.id,\n          description: `OpenAI model: ${model.id}`,\n          contextLength: this.getContextLength(model.id),\n          capabilities: this.getModelCapabilities(model.id),\n          supportsFunctions:\n            model.id.includes('gpt-4') || model.id.includes('gpt-3.5'),\n          supportsVision: model.id.includes('vision') || model.id === 'gpt-4o',\n        }));\n    } catch (error) {\n      throw this.mapError(error);\n    }\n  }\n\n  /**\n   * Get the capabilities supported by this OpenAI provider\n   * @returns Promise resolving to provider capabilities\n   *\n   * @example\n   * ```typescript\n   * const caps = await provider.getCapabilities();\n   * if (caps.functions) {\n   *   // Provider supports function calling\n   * }\n   * ```\n   */\n  async getCapabilities(): Promise<AICapabilities> {\n    return {\n      chat: true,\n      completion: true,\n      embeddings: true,\n      streaming: true,\n      functions: true,\n      vision: true,\n      fineTuning: true,\n      maxContextLength: 128000,\n      supportedOperations: [\n        'chat',\n        'completion',\n        'embedding',\n        'streaming',\n        'functions',\n        'vision',\n      ],\n    };\n  }\n\n  /**\n   * Maps internal AI messages to OpenAI's message format\n   * @param messages - Array of internal AI messages\n   * @returns Array of OpenAI-compatible message parameters\n   * @private\n   */\n  private mapMessagesToOpenAI(\n    messages: AIMessage[],\n  ): OpenAI.Chat.ChatCompletionMessageParam[] {\n    return messages.map((message) => {\n      // Build message based on role and content\n      const baseMessage = {\n        role: message.role as OpenAI.Chat.ChatCompletionRole,\n        content: message.content,\n      };\n\n      // Add optional fields based on role and availability\n      if (\n        message.name &&\n        (message.role === 'system' ||\n          message.role === 'user' ||\n          message.role === 'function')\n      ) {\n        (baseMessage as any).name = message.name;\n      }\n\n      if (message.tool_calls && message.role === 'assistant') {\n        (baseMessage as any).tool_calls = message.tool_calls;\n      }\n\n      return baseMessage as OpenAI.Chat.ChatCompletionMessageParam;\n    });\n  }\n\n  /**\n   * Maps internal tool choice format to OpenAI's tool choice format\n   * @param toolChoice - Internal tool choice specification\n   * @returns OpenAI-compatible tool choice option or undefined\n   * @private\n   */\n  private mapToolChoice(\n    toolChoice?:\n      | 'auto'\n      | 'none'\n      | { type: 'function'; function: { name: string } },\n  ): OpenAI.Chat.ChatCompletionToolChoiceOption | undefined {\n    if (!toolChoice) return undefined;\n    if (typeof toolChoice === 'string') return toolChoice;\n    return {\n      type: 'function',\n      function: { name: toolChoice.function.name },\n    };\n  }\n\n  /**\n   * Maps OpenAI usage information to internal token usage format\n   * @param usage - OpenAI usage object from API response\n   * @returns Internal token usage object or undefined\n   * @private\n   */\n  private mapUsage(\n    usage?:\n      | OpenAI.CompletionUsage\n      | OpenAI.Completions.CompletionUsage\n      | OpenAI.Embeddings.CreateEmbeddingResponse.Usage,\n  ): TokenUsage | undefined {\n    if (!usage) return undefined;\n    return {\n      promptTokens: usage.prompt_tokens || 0,\n      completionTokens: (usage as any).completion_tokens || 0,\n      totalTokens: usage.total_tokens || 0,\n    };\n  }\n\n  /**\n   * Maps OpenAI finish reason to internal finish reason format\n   * @param reason - OpenAI finish reason from API response\n   * @returns Internal finish reason\n   * @private\n   */\n  private mapFinishReason(reason: string | null): AIResponse['finishReason'] {\n    switch (reason) {\n      case 'stop':\n        return 'stop';\n      case 'length':\n        return 'length';\n      case 'tool_calls':\n        return 'tool_calls';\n      case 'content_filter':\n        return 'content_filter';\n      default:\n        return 'stop';\n    }\n  }\n\n  /**\n   * Gets the context length for a given OpenAI model\n   * @param modelId - The OpenAI model identifier\n   * @returns Maximum context length in tokens\n   * @private\n   */\n  private getContextLength(modelId: string): number {\n    if (modelId.includes('gpt-4o')) return 128000;\n    if (modelId.includes('gpt-4-turbo')) return 128000;\n    if (modelId.includes('gpt-4')) return 8192;\n    if (modelId.includes('gpt-3.5-turbo')) return 16385;\n    return 4096;\n  }\n\n  /**\n   * Gets the capabilities for a given OpenAI model\n   * @param modelId - The OpenAI model identifier\n   * @returns Array of capability strings\n   * @private\n   */\n  private getModelCapabilities(modelId: string): string[] {\n    const capabilities = ['text'];\n    if (modelId.includes('gpt')) {\n      capabilities.push('chat', 'functions');\n    }\n    if (modelId.includes('vision') || modelId === 'gpt-4o') {\n      capabilities.push('vision');\n    }\n    if (modelId.includes('embedding')) {\n      capabilities.push('embeddings');\n    }\n    return capabilities;\n  }\n\n  /**\n   * Maps OpenAI API errors to internal AI error types\n   * @param error - The error object from OpenAI API\n   * @returns Appropriate internal AI error instance\n   * @private\n   */\n  private mapError(error: unknown): AIError {\n    if (error instanceof OpenAI.APIError) {\n      switch (error.status) {\n        case 401:\n          return new AuthenticationError('openai');\n        case 429: {\n          // Try to extract retry-after from headers\n          const retryAfter = error.headers?.['retry-after'];\n          const retryAfterSeconds = retryAfter\n            ? Number.parseInt(retryAfter, 10)\n            : undefined;\n          return new RateLimitError('openai', retryAfterSeconds);\n        }\n        case 404:\n          return new ModelNotFoundError(error.message, 'openai');\n        case 413:\n          return new ContextLengthError('openai');\n        default:\n          if (error.message.includes('content_filter')) {\n            return new ContentFilterError('openai');\n          }\n          return new AIError(error.message, 'API_ERROR', 'openai');\n      }\n    }\n\n    if (error instanceof AIError) {\n      return error;\n    }\n\n    const errorMessage =\n      error instanceof Error ? error.message : 'Unknown error occurred';\n    return new AIError(errorMessage, 'UNKNOWN_ERROR', 'openai');\n  }\n}\n"],"names":[],"mappings":";;AAqCO,MAAM,eAAsC;AAAA,EACzC;AAAA,EACA;AAAA;AAAA;AAAA;AAAA;AAAA,EAMR,YAAY,SAAwB;AAClC,SAAK,UAAU;AAAA,MACb,cAAc;AAAA,MACd,GAAG;AAAA,IAAA;AAGL,SAAK,SAAS,IAAI,OAAO;AAAA,MACvB,QAAQ,KAAK,QAAQ;AAAA,MACrB,SAAS,KAAK,QAAQ;AAAA,MACtB,cAAc,KAAK,QAAQ;AAAA,MAC3B,SAAS,KAAK,QAAQ;AAAA,MACtB,YAAY,KAAK,QAAQ;AAAA,MACzB,gBAAgB,KAAK,QAAQ;AAAA,IAAA,CAC9B;AAAA,EACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAsBA,MAAM,KACJ,UACA,UAAuB,IACF;AACrB,QAAI;AACF,YAAM,WAAW,MAAM,KAAK,OAAO,KAAK,YAAY,OAAO;AAAA,QACzD,OAAO,QAAQ,SAAS,KAAK,QAAQ,gBAAgB;AAAA,QACrD,UAAU,KAAK,oBAAoB,QAAQ;AAAA,QAC3C,YAAY,QAAQ;AAAA,QACpB,aAAa,QAAQ;AAAA,QACrB,OAAO,QAAQ;AAAA,QACf,GAAG,QAAQ;AAAA,QACX,MAAM,QAAQ;AAAA,QACd,mBAAmB,QAAQ;AAAA,QAC3B,kBAAkB,QAAQ;AAAA,QAC1B,MAAM,QAAQ;AAAA,QACd,OAAO,QAAQ,OAAO,IAAI,CAAC,UAAU;AAAA,UACnC,MAAM;AAAA,UACN,UAAU;AAAA,YACR,MAAM,KAAK,SAAS;AAAA,YACpB,aAAa,KAAK,SAAS;AAAA,YAC3B,YAAY,KAAK,SAAS;AAAA,UAAA;AAAA,QAC5B,EACA;AAAA,QACF,aAAa,KAAK,cAAc,QAAQ,UAAU;AAAA,QAClD,iBAAiB,QAAQ;AAAA,QACzB,MAAM,QAAQ;AAAA,QACd,QAAQ;AAAA,MAAA,CACT;AAED,YAAM,SAAS,SAAS,QAAQ,CAAC;AACjC,UAAI,CAAC,QAAQ;AACX,cAAM,IAAI;AAAA,UACR;AAAA,UACA;AAAA,UACA;AAAA,QAAA;AAAA,MAEJ;AAEA,aAAO;AAAA,QACL,SAAS,OAAO,QAAQ,WAAW;AAAA,QACnC,OAAO,KAAK,SAAS,SAAS,KAAK;AAAA,QACnC,OAAO,SAAS;AAAA,QAChB,cAAc,KAAK,gBAAgB,OAAO,aAAa;AAAA,QACvD,WAAW,OAAO,QAAQ,YACtB,OAAO,CAAC,SAAS,KAAK,SAAS,UAAU,EAC1C,IAAI,CAAC,UAAU;AAAA,UACd,IAAI,KAAK;AAAA,UACT,MAAM;AAAA,UACN,UAAU;AAAA,YACR,MAAM,KAAK,SAAS;AAAA,YACpB,WAAW,KAAK,SAAS;AAAA,UAAA;AAAA,QAC3B,EACA;AAAA,MAAA;AAAA,IAER,SAAS,OAAO;AACd,YAAM,KAAK,SAAS,KAAK;AAAA,IAC3B;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAkBA,MAAM,SACJ,QACA,UAA6B,IACR;AACrB,WAAO,KAAK,KAAK,CAAC,EAAE,MAAM,QAAQ,SAAS,OAAA,CAAQ,GAAG;AAAA,MACpD,OAAO,QAAQ;AAAA,MACf,WAAW,QAAQ;AAAA,MACnB,aAAa,QAAQ;AAAA,MACrB,MAAM,QAAQ;AAAA,MACd,GAAG,QAAQ;AAAA,MACX,MAAM,QAAQ;AAAA,MACd,QAAQ,QAAQ;AAAA,MAChB,YAAY,QAAQ;AAAA,IAAA,CACrB;AAAA,EACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAoBA,MAAM,MACJ,MACA,UAA4B,IACA;AAC5B,QAAI;AACF,YAAM,QAAQ,MAAM,QAAQ,IAAI,IAAI,OAAO,CAAC,IAAI;AAChD,YAAM,WAAW,MAAM,KAAK,OAAO,WAAW,OAAO;AAAA,QACnD,OAAO,QAAQ,SAAS;AAAA,QACxB;AAAA,QACA,iBAAiB,QAAQ;AAAA,QACzB,YAAY,QAAQ;AAAA,QACpB,MAAM,QAAQ;AAAA,MAAA,CACf;AAED,aAAO;AAAA,QACL,YAAY,SAAS,KAAK,IAAI,CAAC,SAAS,KAAK,SAAS;AAAA,QACtD,OAAO,KAAK,SAAS,SAAS,KAAK;AAAA,QACnC,OAAO,SAAS;AAAA,MAAA;AAAA,IAEpB,SAAS,OAAO;AACd,YAAM,KAAK,SAAS,KAAK;AAAA,IAC3B;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAkBA,OAAO,OACL,UACA,UAAuB,IACA;AACvB,QAAI;AACF,YAAM,SAAS,MAAM,KAAK,OAAO,KAAK,YAAY,OAAO;AAAA,QACvD,OAAO,QAAQ,SAAS,KAAK,QAAQ,gBAAgB;AAAA,QACrD,UAAU,KAAK,oBAAoB,QAAQ;AAAA,QAC3C,YAAY,QAAQ;AAAA,QACpB,aAAa,QAAQ;AAAA,QACrB,OAAO,QAAQ;AAAA,QACf,MAAM,QAAQ;AAAA,QACd,mBAAmB,QAAQ;AAAA,QAC3B,kBAAkB,QAAQ;AAAA,QAC1B,MAAM,QAAQ;AAAA,QACd,QAAQ;AAAA,MAAA,CACT;AAED,uBAAiB,SAAS,QAAQ;AAChC,cAAM,UAAU,MAAM,QAAQ,CAAC,GAAG,OAAO;AACzC,YAAI,SAAS;AACX,cAAI,QAAQ,YAAY;AACtB,oBAAQ,WAAW,OAAO;AAAA,UAC5B;AACA,gBAAM;AAAA,QACR;AAAA,MACF;AAAA,IACF,SAAS,OAAO;AACd,YAAM,KAAK,SAAS,KAAK;AAAA,IAC3B;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAkBA,MAAM,YAAY,MAA+B;AAG/C,WAAO,KAAK,KAAK,KAAK,SAAS,CAAC;AAAA,EAClC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAaA,MAAM,YAAgC;AACpC,QAAI;AACF,YAAM,WAAW,MAAM,KAAK,OAAO,OAAO,KAAA;AAC1C,aAAO,SAAS,KACb;AAAA,QACC,CAAC,UACC,MAAM,GAAG,SAAS,KAAK,KAAK,MAAM,GAAG,SAAS,gBAAgB;AAAA,MAAA,EAEjE,IAAI,CAAC,WAAW;AAAA,QACf,IAAI,MAAM;AAAA,QACV,MAAM,MAAM;AAAA,QACZ,aAAa,iBAAiB,MAAM,EAAE;AAAA,QACtC,eAAe,KAAK,iBAAiB,MAAM,EAAE;AAAA,QAC7C,cAAc,KAAK,qBAAqB,MAAM,EAAE;AAAA,QAChD,mBACE,MAAM,GAAG,SAAS,OAAO,KAAK,MAAM,GAAG,SAAS,SAAS;AAAA,QAC3D,gBAAgB,MAAM,GAAG,SAAS,QAAQ,KAAK,MAAM,OAAO;AAAA,MAAA,EAC5D;AAAA,IACN,SAAS,OAAO;AACd,YAAM,KAAK,SAAS,KAAK;AAAA,IAC3B;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAcA,MAAM,kBAA2C;AAC/C,WAAO;AAAA,MACL,MAAM;AAAA,MACN,YAAY;AAAA,MACZ,YAAY;AAAA,MACZ,WAAW;AAAA,MACX,WAAW;AAAA,MACX,QAAQ;AAAA,MACR,YAAY;AAAA,MACZ,kBAAkB;AAAA,MAClB,qBAAqB;AAAA,QACnB;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,MAAA;AAAA,IACF;AAAA,EAEJ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQQ,oBACN,UAC0C;AAC1C,WAAO,SAAS,IAAI,CAAC,YAAY;AAE/B,YAAM,cAAc;AAAA,QAClB,MAAM,QAAQ;AAAA,QACd,SAAS,QAAQ;AAAA,MAAA;AAInB,UACE,QAAQ,SACP,QAAQ,SAAS,YAChB,QAAQ,SAAS,UACjB,QAAQ,SAAS,aACnB;AACC,oBAAoB,OAAO,QAAQ;AAAA,MACtC;AAEA,UAAI,QAAQ,cAAc,QAAQ,SAAS,aAAa;AACrD,oBAAoB,aAAa,QAAQ;AAAA,MAC5C;AAEA,aAAO;AAAA,IACT,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQQ,cACN,YAIwD;AACxD,QAAI,CAAC,WAAY,QAAO;AACxB,QAAI,OAAO,eAAe,SAAU,QAAO;AAC3C,WAAO;AAAA,MACL,MAAM;AAAA,MACN,UAAU,EAAE,MAAM,WAAW,SAAS,KAAA;AAAA,IAAK;AAAA,EAE/C;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQQ,SACN,OAIwB;AACxB,QAAI,CAAC,MAAO,QAAO;AACnB,WAAO;AAAA,MACL,cAAc,MAAM,iBAAiB;AAAA,MACrC,kBAAmB,MAAc,qBAAqB;AAAA,MACtD,aAAa,MAAM,gBAAgB;AAAA,IAAA;AAAA,EAEvC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQQ,gBAAgB,QAAmD;AACzE,YAAQ,QAAA;AAAA,MACN,KAAK;AACH,eAAO;AAAA,MACT,KAAK;AACH,eAAO;AAAA,MACT,KAAK;AACH,eAAO;AAAA,MACT,KAAK;AACH,eAAO;AAAA,MACT;AACE,eAAO;AAAA,IAAA;AAAA,EAEb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQQ,iBAAiB,SAAyB;AAChD,QAAI,QAAQ,SAAS,QAAQ,EAAG,QAAO;AACvC,QAAI,QAAQ,SAAS,aAAa,EAAG,QAAO;AAC5C,QAAI,QAAQ,SAAS,OAAO,EAAG,QAAO;AACtC,QAAI,QAAQ,SAAS,eAAe,EAAG,QAAO;AAC9C,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQQ,qBAAqB,SAA2B;AACtD,UAAM,eAAe,CAAC,MAAM;AAC5B,QAAI,QAAQ,SAAS,KAAK,GAAG;AAC3B,mBAAa,KAAK,QAAQ,WAAW;AAAA,IACvC;AACA,QAAI,QAAQ,SAAS,QAAQ,KAAK,YAAY,UAAU;AACtD,mBAAa,KAAK,QAAQ;AAAA,IAC5B;AACA,QAAI,QAAQ,SAAS,WAAW,GAAG;AACjC,mBAAa,KAAK,YAAY;AAAA,IAChC;AACA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQQ,SAAS,OAAyB;AACxC,QAAI,iBAAiB,OAAO,UAAU;AACpC,cAAQ,MAAM,QAAA;AAAA,QACZ,KAAK;AACH,iBAAO,IAAI,oBAAoB,QAAQ;AAAA,QACzC,KAAK,KAAK;AAER,gBAAM,aAAa,MAAM,UAAU,aAAa;AAChD,gBAAM,oBAAoB,aACtB,OAAO,SAAS,YAAY,EAAE,IAC9B;AACJ,iBAAO,IAAI,eAAe,UAAU,iBAAiB;AAAA,QACvD;AAAA,QACA,KAAK;AACH,iBAAO,IAAI,mBAAmB,MAAM,SAAS,QAAQ;AAAA,QACvD,KAAK;AACH,iBAAO,IAAI,mBAAmB,QAAQ;AAAA,QACxC;AACE,cAAI,MAAM,QAAQ,SAAS,gBAAgB,GAAG;AAC5C,mBAAO,IAAI,mBAAmB,QAAQ;AAAA,UACxC;AACA,iBAAO,IAAI,QAAQ,MAAM,SAAS,aAAa,QAAQ;AAAA,MAAA;AAAA,IAE7D;AAEA,QAAI,iBAAiB,SAAS;AAC5B,aAAO;AAAA,IACT;AAEA,UAAM,eACJ,iBAAiB,QAAQ,MAAM,UAAU;AAC3C,WAAO,IAAI,QAAQ,cAAc,iBAAiB,QAAQ;AAAA,EAC5D;AACF;"}